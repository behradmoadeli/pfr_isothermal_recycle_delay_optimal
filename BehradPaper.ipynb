{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ByIufqrO7oiy"
   },
   "source": [
    "Loading the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1674594709346,
     "user": {
      "displayName": "Guilherme Ozorio Cassol",
      "userId": "16524009092046304621"
     },
     "user_tz": 420
    },
    "id": "uEGAWDi23_da"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as lina\n",
    "import scipy.optimize as opt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os # Flexible loading and saving dataframs from/to csv files\n",
    "import ast # Module to parse string representations of dictionaries\n",
    "import hdbscan # For clustering solution dataframes\n",
    "from sklearn.preprocessing import StandardScaler # Used in clustering function\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1l2-KpYqZSK"
   },
   "source": [
    "# System Model\n",
    "\n",
    "Initially, only the equation for one state (temperature or concentration) will be considered. For simplicity, the domain will be $[0,1]$, with Danckwerts boundary conditions:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l} \\dot{x} = D\\partial_{\\zeta\\zeta} x -v\\partial_{\\zeta} x +kx\\\\\n",
    "D\\partial_\\zeta x(0,t)-vx(0,t)=-v[Rx(1,t-\\tau)+(1-R)u(t-\\tau_I)] \\\\\n",
    "\\partial_\\zeta x(1,t)=0 \\\\\n",
    "y(t)=x(1,t-\\tau_O)\n",
    "  \\end{array}\\right. $$\n",
    "\n",
    "This model considers that the input is applied in the reactor's entrance, which is mixed with the recycle from the outlet. Input, output, and state delays are considered and represented by $\\tau_I,\\tau_O$, and $\\tau$, respectively. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing system parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pars = {\n",
    "    'k':10,\n",
    "    'D':0.1,\n",
    "    'v':0.5,\n",
    "    'tau':1,\n",
    "    'R':0.9,\n",
    "    'label':'default'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalue Analysis\n",
    "\n",
    "The eigenvalue problem, defined as $A\\Phi(\\zeta,\\lambda)=\\lambda\\Phi(\\zeta,\\lambda)$, will result in the following system of equation for this system:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l} \\lambda\\phi = D\\partial_{\\zeta\\zeta} \\phi -v\\partial_{\\zeta} \\phi +k\\phi\\\\\n",
    "\\lambda\\phi_D=\\dfrac{1}{\\tau}\\partial_{\\zeta}\\phi_D\\\\\n",
    "D\\partial_\\zeta \\phi(0)-v\\phi(0)=-Rv\\phi_D(0) \\\\\n",
    "\\partial_\\zeta \\phi(1)=0 \\\\\n",
    "\\phi_D(1)=\\phi(1)\\\\\n",
    "  \\end{array}\\right. $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\Phi=[\\phi,\\,\\phi_D]^T$, with $\\phi$ as the state eigenfunction and $\\phi_D$ as the eigenfunction related to the delay. By defining $X=[\\phi,\\, \\partial_{\\zeta}\\phi,\\,\\phi_D]^T$, the following system of ODEs is obtained:\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\\partial_{\\zeta}X=\\begin{bmatrix} 0 & 1 & 0\\\\ \\dfrac{\\lambda-k}{D} & \\dfrac{v}{D} & 0\\\\0 & 0 & \\tau\\lambda\\end{bmatrix}X=Î›X \\\\\n",
    "DX_2(0)-vX_1(0)=-RvX_3(0) \\\\\n",
    "X_2(1)=0 \\\\\n",
    "X_3(1)=X_1(1)\\\\ \\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristic Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a system of first order ODE's, and the solution to such systems is given by:\n",
    "\n",
    "$$ X(\\zeta, \\lambda) = e^{\\Lambda \\zeta} X (\\zeta=0, \\lambda) \\\\ \\overset{\\zeta = 1}{\\Rightarrow} X(1, \\lambda) = e^{\\Lambda} X (\\zeta=0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's assume:\n",
    "\n",
    "$$ e^{\\Lambda} = Q(\\lambda) = \\begin{bmatrix} \n",
    "        q_{1} & q_{2} & q_{3} \\\\ q_{4} & q_{5} & q_{6} \\\\ q_{7} & q_{8} & q_{9}\n",
    "    \\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we may write:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "X_1(1) = q_1 X_1(0) + q_2 X_2(0) + q_3 X_3(0) \\\\\n",
    "X_2(1) = q_4 X_1(0) + q_5 X_2(0) + q_6 X_3(0) \\\\\n",
    "X_3(1) = q_7 X_1(0) + q_8 X_2(0) + q_9 X_3(0)\n",
    "\\end{array}\\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we may go ahead and put the above expressions into boundary conditions to get the following:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "Dx_2-vx_1=-Rvx_3 \\\\\n",
    "q_4 x_1 + q_5 x_2 + q_6 x_3 = 0 \\\\\n",
    "q_7 x_1 + q_8 x_2 + q_9 x_3 = q_1 x_1 + q_2 x_2 + q_3 x_3\n",
    "\\end{array}\\right. \\Rightarrow \\left\\{\\begin{array}{l}\n",
    "-vx_1 + Dx_2 + Rvx_3 = 0 \\\\\n",
    "q_4 x_1 + q_5 x_2 + q_6 x_3 = 0 \\\\\n",
    "(q_1 - q_7) x_1 + (q_2 - q_8) x_2 + (q_3 - q_9) x_3 = 0\n",
    "\\end{array}\\right.$$\n",
    "\n",
    "\n",
    "where $x_i$ is the same as $X_i(0)$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular case, we know that:\n",
    "\n",
    "$$ q_{3} = q_{6} = q_{7} = q_{8} = 0 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will further simplify the above system of equions into the following system:\n",
    "\n",
    "$$\\left\\{\\begin{array}{l}\n",
    "-vx_1 + Dx_2 + Rvx_3 = 0 \\\\\n",
    "q_4 x_1 + q_5 x_2 = 0 \\\\\n",
    "q_1 x_1 + q_2 x_2 - q_9 x_3 = 0\n",
    "\\end{array}\\right.$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a $3 \\times 3$ system of algebraic equations in the form of $\\bar{A} \\bar{x} = 0 $, with:\n",
    "\n",
    "$$ \\bar{A} = \\begin{bmatrix}\n",
    "-v & D & Rv \\\\\n",
    "q_4 & q_5 & 0 \\\\\n",
    "q_1 & q_2 & -q_9\n",
    "\\end{bmatrix}; \\quad \\bar{x} = \\begin{bmatrix}\n",
    "x_1 \\\\ x_2 \\\\ x_3\n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Edit below*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For such a system to have non-trivial solution (i.e. $\\bar{x} \\neq 0$), the dimension of the nullspace of the coefficients matrix $\\bar{A}$ needs to be non-zero. This will happen if and only if the coefficients matrix $\\bar{A}$ is rank-deficient. One way to make sure matrix $ \\bar{A} $ is not full-rank, is to set a linear combination of its rows to be zero, with non-zero coefficients. Multiplying the second row of the matrix by $\\alpha$ and the third row by $\\beta$, we can write:\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "-v + \\alpha q_4 + \\beta q_1 = 0 \\\\\n",
    "D + \\alpha q_5 + \\beta q_2 = 0 \\\\\n",
    "-Rv - \\beta q_9 = 0 \n",
    "\\end{array}\\right.\n",
    "\\Rightarrow\n",
    "\\left\\{\\begin{array}{l}\n",
    "\\alpha q_4 + \\beta q_1 = v \\\\\n",
    "\\alpha q_5 + \\beta q_2 = -D \\\\\n",
    "\\beta q_9 = -Rv \n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above system is a system of 3 equations and 3 unknowns (i.e. $\\alpha$, $\\beta$, and $\\lambda$, with $\\lambda$ being hidden in $q_i$ terms). By writing $\\alpha$ and $\\beta$ variables based on $q_i$ terms, we can get the characteristic equation.\n",
    "\n",
    "Using the third equation, we can get:\n",
    "\n",
    "$$ \\beta = \\frac{-Rv}{q_9} $$\n",
    "\n",
    "Using the above equation to replace $\\beta$ into the second equation will result in:\n",
    "\n",
    "$$ \\alpha = \\frac{v}{q_4} \\left(1 + \\frac{R q_1}{q_9} \\right) $$\n",
    "\n",
    "Therefore, we can put the above expressions for $\\alpha$ and $\\beta$ into the first equation to get the characteristic equation, which is a non-linear function of the eigenvalue of the system, $\\lambda$:\n",
    "\n",
    "$$ f(\\lambda) = D + v \\frac{q_5}{q_4} \\left( 1 + \\frac{R q_1}{q_9} \\right) - Rv \\frac{q_2}{q_9} = 0 $$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now multiply both sides of the charactersitic equation by $q_4 q_9$ to avoid numerical errors while solfing for $f(\\lambda)$. This will give:\n",
    "\n",
    "$$ g(\\lambda) = D q_4 q_9 + v [ q_5 q_9 + R (q_1 q_5 - q_2 q_4)] = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a handful of functions to ease the following tasks:\n",
    "\n",
    "- Writing solution dataframes to csv files with corresponding parameters as their filename, which may also contain other data as their first line.\n",
    "- Reading those csv files created above and saving them into a dataframe, with correct label ad metadata.\n",
    "- Reading csv files containing different sets of parameters and saving them to a list of dictionaries, with each parameters set being a dictionary.\n",
    "- clustering duplicate eigenvalues in the resulting dataframe using two methods:\n",
    "    - Utilizing significant digits\n",
    "    - Using HDBSCAN clustering method\n",
    "- Plotting a single dataframe of solutions\n",
    "- Plotting a series of solutions, each with diferent title (parameters set) to compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_csv(df, filename, parent_dir=None, metadata=None):\n",
    "    \"\"\"\n",
    "    Save a DataFrame to a CSV file, optionally with metadata in the first line.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to be saved.\n",
    "        filename (str): The name of the output CSV file.\n",
    "        parent_dir (str, optional): The parent directory to save the file in. If None, saves in the current directory.\n",
    "        metadata (str, optional): Metadata to be stored in the first line of the CSV file as a comment.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if parent_dir:\n",
    "        if not os.path.exists(parent_dir):\n",
    "            os.makedirs(parent_dir)\n",
    "        output_filepath = os.path.join(parent_dir, filename)\n",
    "    else:\n",
    "        output_filepath = filename\n",
    "    \n",
    "    counter = 1\n",
    "    while os.path.exists(output_filepath):\n",
    "        # If the file already exists, generate a new filename with an incremental suffix\n",
    "        base_name, ext = os.path.splitext(filename)\n",
    "        output_filepath = os.path.join(parent_dir, f\"{base_name}_{counter}{ext}\")\n",
    "        counter += 1\n",
    "        \n",
    "    if metadata is None:\n",
    "        df.to_csv(output_filepath, index=False)\n",
    "        print(f\"DataFrame saved to {output_filepath}\")\n",
    "    else:\n",
    "        with open(output_filepath, 'w') as f:\n",
    "            f.write(f\"# {metadata}\\n\")\n",
    "            df.to_csv(f, index=False)\n",
    "        print(f\"DataFrame with metadata '{metadata}' saved to {output_filepath}\")\n",
    "\n",
    "def load_dataframe_from_csv(input_filepath):\n",
    "    \"\"\"\n",
    "    Load a DataFrame from a CSV file, along with metadata if present in the first line.\n",
    "\n",
    "    Args:\n",
    "        input_filepath (str): The path to the input CSV file.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame.\n",
    "        str: The base filename (without extension) of the input file.\n",
    "        str or None: Metadata if present, else None.\n",
    "    \"\"\"\n",
    "    with open(input_filepath, 'r') as f:\n",
    "        metadata_line = f.readline().strip()\n",
    "        if metadata_line.startswith('#'):\n",
    "            metadata = metadata_line.lstrip('# ').strip()\n",
    "            df = pd.read_csv(input_filepath, comment='#')\n",
    "        else:\n",
    "            metadata = None\n",
    "            df = pd.read_csv(input_filepath)\n",
    "    \n",
    "    base_filename = os.path.splitext(os.path.basename(input_filepath))[0]\n",
    "    return df, base_filename, metadata\n",
    "\n",
    "def create_custom_pars_list(csv_path):\n",
    "    \"\"\"\n",
    "    Create a list of custom parameter dictionaries from a CSV file.\n",
    "\n",
    "    This function reads a CSV file located at the given path and constructs a list\n",
    "    of dictionaries, where each dictionary represents custom parameters based on\n",
    "    the CSV content and a global default_pars dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        csv_path (str): The path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing custom parameter sets.\n",
    "    \"\"\"\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Initialize a list to store dictionaries\n",
    "    custom_pars_list = []\n",
    "    \n",
    "    # Use the global default_pars variable\n",
    "    global default_pars\n",
    "\n",
    "    # Iterate through the rows of the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        custom_pars = default_pars.copy()\n",
    "        \n",
    "        # Update custom_pars with values from the current row\n",
    "        for key in default_pars.keys():\n",
    "            if key in row:\n",
    "                custom_pars[key] = row[key]\n",
    "        \n",
    "        # Append the customized parameter dictionary to the list\n",
    "        custom_pars_list.append(custom_pars)\n",
    "    \n",
    "    return custom_pars_list\n",
    "\n",
    "def significant_digits(x, n):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    return n - int(np.floor(np.log10(abs(x)))) - 1\n",
    "\n",
    "def process_dataframe(df, n):\n",
    "    \"\"\"\n",
    "    Process a pandas DataFrame by adding an 'instances' column, rounding values,\n",
    "    and handling duplicates. Also replaces small 'Sol_i' values with zero.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame with 'Sol_r' and 'Sol_i' columns.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: Processed DataFrame with 'instances' column updated.\n",
    "    \"\"\"\n",
    "    # Add a new column 'instances' with default value 1\n",
    "    df['instances'] = 1\n",
    "    \n",
    "    # Create a dictionary to keep track of unique rounded values\n",
    "    unique_values = {}\n",
    "    \n",
    "    \n",
    "    # Iterate through rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Replace small 'Sol_i' values with zero\n",
    "        sol_i = row['Sol_i']\n",
    "        if sol_i < 1e-8:\n",
    "            sol_i = 0\n",
    "        \n",
    "        # Round the values to 5 significant digits\n",
    "        rounded_r = round(row['Sol_r'], significant_digits(row['Sol_r'], n))\n",
    "        rounded_i = round(sol_i, significant_digits(sol_i, n))\n",
    "        \n",
    "        # Check if the rounded values have been encountered before\n",
    "        rounded_key = (rounded_r, rounded_i)\n",
    "        if rounded_key in unique_values:\n",
    "            # Increment 'instances' of the existing row\n",
    "            existing_index = unique_values[rounded_key]\n",
    "            df.at[existing_index, 'instances'] += 1\n",
    "            df.drop(index, inplace=True)  # Remove the current row\n",
    "        else:\n",
    "            unique_values[rounded_key] = index\n",
    "    \n",
    "    return df\n",
    "    \n",
    "def cluster(input_df, min_cluster_size):\n",
    "    \"\"\"\n",
    "    Generate a representative DataFrame from an input DataFrame using HDBSCAN clustering.\n",
    "\n",
    "    Parameters:\n",
    "        input_df (pd.DataFrame): The input DataFrame with 'x' and 'y' columns.\n",
    "        min_cluster_size (int): Minimum number of points to form a cluster (default is 2).\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing one representative point from each cluster.\n",
    "    \"\"\"\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    points_scaled = scaler.fit_transform(input_df[ ['Sol_r', 'Sol_i']])\n",
    "    \n",
    "    # Apply HDBSCAN clustering\n",
    "    hdbscan_clusterer = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    labels = hdbscan_clusterer.fit_predict(points_scaled)\n",
    "    \n",
    "    # Create a new DataFrame with one representative point from each cluster\n",
    "    unique_labels = set(labels)\n",
    "    representative_points = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        if label != -1:\n",
    "            cluster_points = input_df[labels == label][ ['Sol_r', 'Sol_i']]\n",
    "            representative_point = cluster_points.iloc[0]\n",
    "            representative_points.append(representative_point)\n",
    "\n",
    "    representative_df = pd.DataFrame(representative_points, columns= ['Sol_r', 'Sol_i'])\n",
    "    return representative_df\n",
    "\n",
    "def plot_single_df(\n",
    "        df, title, metadata, filter=True,\n",
    "        real_lower_bound=-200, real_upper_bound=50, imag_lower_bound=-5, imag_upper_bound=5\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Plot a DataFrame based on several inputs.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        title (str): Title for the plot.\n",
    "        metadata (dict): Dictionary containing metadata information.\n",
    "        filter_real (float): Minimum value for real part.\n",
    "        filter_imag (float): Absolute maximum value for imaginary part.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    if filter:\n",
    "        # Filter rows based on criteria\n",
    "        filtered_df = df[\n",
    "            (df['Sol_r'] > real_lower_bound) &\n",
    "            (df['Sol_r'] < real_upper_bound) &\n",
    "            (df['Sol_i'] > imag_lower_bound) &\n",
    "            (df['Sol_i'] < imag_upper_bound)\n",
    "        ]\n",
    "    else:\n",
    "        filtered_df = df\n",
    "    \n",
    "    # Scatter plot\n",
    "    ax.scatter(filtered_df['Sol_r'], filtered_df['Sol_i'])\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Sol_r')\n",
    "    ax.set_ylabel('Sol_i')\n",
    "    \n",
    "    # Set axis limits to ensure visibility of x=0 and y=0 lines\n",
    "    ax.axhline(0, color='black', linewidth=0.5)  # Horizontal line at y=0\n",
    "    ax.axvline(0, color='black', linewidth=0.5)  # Vertical line at x=0\n",
    "    ax.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Print metadata\n",
    "    for key, value in metadata.items():\n",
    "        print(f'{key} : {value}')\n",
    "\n",
    "def plot_multiple_datasets(parent_directory, rows=None, cols=None, figsize=None, **kwargs):\n",
    "    \"\"\"\n",
    "    Plot multiple datasets from CSV files in a grid layout.\n",
    "\n",
    "    Args:\n",
    "        parent_directory (str): The directory containing CSV files to plot.\n",
    "        rows (int, optional): Number of rows in the grid. If None, calculated based on dataset count.\n",
    "        cols (int, optional): Number of columns in the grid. If None, calculated based on dataset count.\n",
    "        figsize (tuple, optional): Figure size (width, height) in inches.\n",
    "        **kwargs: Additional keyword arguments to pass to matplotlib.subplots().\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # List all CSV files in the parent directory\n",
    "    csv_files = [file for file in os.listdir(parent_directory) if file.endswith('.csv')]\n",
    "    results = []\n",
    "\n",
    "    # Load dataframes from CSV files and categorize into 'default' and other datasets\n",
    "    for csv_file in csv_files:\n",
    "        csv_path = os.path.join(parent_directory, csv_file)\n",
    "        df, base_filename, metadata = load_dataframe_from_csv(csv_path)\n",
    "        if base_filename == 'Default':\n",
    "            default = df\n",
    "        else:\n",
    "            results.append((df, base_filename, metadata))\n",
    "\n",
    "    # Extract datasets and calculate the number of datasets\n",
    "    datasets = [result[0] for result in results]\n",
    "    num_datasets = len(datasets)\n",
    "\n",
    "    # Calculate rows and columns for the grid layout if not specified\n",
    "    if rows is None and cols is None:\n",
    "        rows = int(np.ceil(np.sqrt(num_datasets)))\n",
    "        cols = int(np.ceil(num_datasets / rows))\n",
    "    elif rows is None:\n",
    "        rows = int(np.ceil(num_datasets / cols))\n",
    "    elif cols is None:\n",
    "        cols = int(np.ceil(num_datasets / rows))\n",
    "\n",
    "    mid_row = int(np.floor(rows/2))\n",
    "\n",
    "    # Set default figure size if not specified\n",
    "    if figsize is None:\n",
    "        figsize = (cols * 4, rows * 3)\n",
    "\n",
    "    # Create the subplots grid\n",
    "    fig, axes = plt.subplots(rows+1, cols, figsize=figsize, **kwargs)\n",
    "\n",
    "    # Flatten the axes array if there's only one dataset\n",
    "    if num_datasets == 1:\n",
    "        axes = np.array([[axes]])\n",
    "\n",
    "    # Iterate through datasets and plot them on the grid\n",
    "    for i, dataset in enumerate(datasets):\n",
    "        row = i % rows  # Calculate current row index\n",
    "        col = i // rows  # Calculate current column index\n",
    "\n",
    "        # Plot default dataset\n",
    "        if row == mid_row:\n",
    "            axes[row, col].plot(default)\n",
    "            axes[row, col].set_title('Default')\n",
    "            row += 1\n",
    "        elif row >= mid_row:\n",
    "            row += 1\n",
    "        \n",
    "        # Plot each dataset\n",
    "        axes[row, col].plot(dataset)\n",
    "        axes[row, col].set_title(f'Dataset {i+1}')\n",
    "\n",
    "    # Remove empty subplots if there are more grids than datasets\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i >= num_datasets + cols:\n",
    "            ax.axis('off')\n",
    "\n",
    "    # Adjust layout and display the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It is necessary to define a function that gives the value of the characteristic equation at each $\\lambda$. This can be later used in the main function, *find_eig()* to get a complete set of solutions. The charachteristic equiation is defined in the function *char_eq(x)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_eq(x): # To be more simplified\n",
    "    \"\"\"\n",
    "    This function evaluates the charachteristic equation at a given point.\n",
    "\n",
    "    Parameters:\n",
    "        x ([float, float]):\n",
    "            A list of 2 elements, making up the Re and Im parts of the complex eigenvalue to calculate char_eq.\n",
    "    \n",
    "    Returns:\n",
    "        array[float, float]:\n",
    "            An array of 2 elements, making up the Re and Im parts of the complex value of char_eq at the given x.\n",
    "    \"\"\"\n",
    "    global global_par # To access 'global_par', defined within 'find_eig()' function as a global variable.\n",
    "    par = global_par\n",
    "    l = complex(x[0], x[1])\n",
    "    \n",
    "    (k, v, D, t, R) = (par['k'], par['v'], par['D'], par['tau'], par['R'])\n",
    "    p = v**2 - 4*D * (k-l)\n",
    "    p_sqrt = np.sqrt(p)\n",
    "    if np.isclose(p_sqrt,0, atol=1e-8):\n",
    "        y = (\n",
    "            np.exp(l*t+v/2/D) * (v**2 + 2*D**2)\n",
    "            + v * (1-R*np.exp(v/D))\n",
    "        )\n",
    "    else:\n",
    "        y = (\n",
    "            np.exp(l*t+v/2/D) * np.sinh(np.sqrt(p)/2/D) * (v**2 + 2*D**2)\n",
    "            + v * np.sqrt(p) * (np.cosh(np.sqrt(p)/2/D)-R*np.exp(v/D))\n",
    "        )\n",
    "\n",
    "    return np.array([y.real, y.imag])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may define a function to find the eigenvalues for the characteristic equation. This function takes the following optional keyword argument:\n",
    "\n",
    "- par (dict): A dictionary containing parameters for the system's matrix. If not provided, keys may be passed separately. Absent keys will take default values.\n",
    "- guess_single (complex): A single initial guess for eigenvalue calculation (real + imaginary part).\n",
    "- guess_range_real (list): A list specifying the range of real parts of initial guess values.\n",
    "- guess_range_imag (list): A list specifying the range of imaginary parts of initial guess values.\n",
    "- tol_fsolve (float): Tolerance for fsolve array-like comaprison to converge.\n",
    "- tol_is_sol (float): Tolerance for a complex solution to be accepted.\n",
    "- round_sig_digits (float): Number of significant digits to either separate two different solutions or merge them as one.\n",
    "\n",
    "It is designed to return a tuple with the following:\n",
    "\n",
    "- solution_df (pandas.DataFrame): DataFrame containing found solutions' information.\n",
    "- label (str): A label describing the customized parameters used for the computation.\n",
    "- metadata (dict): A dictionary containing input arguments values used in the computation, other than the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_eig(**kwargs):\n",
    "    \"\"\"\n",
    "    This function solves the char equation in complex plane for different initial guesses.\n",
    "\n",
    "    Parameters:\n",
    "        **kwargs (keyword arguments):            \n",
    "            - par (dict): A dictionary containing parameters for the system's matrix. If not provided, keys may be passed separately. Absent keys will take default values.\n",
    "            - guess_single (complex): A single initial guess for eigenvalue calculation (real + imaginary part).\n",
    "            - guess_range_real (list): A list specifying the range of real parts of initial guess values.\n",
    "            - guess_range_imag (list): A list specifying the range of imaginary parts of initial guess values.\n",
    "            - tol_fsolve (float): Tolerance for fsolve array-like comaprison to converge.\n",
    "            - tol_is_sol (float): Tolerance for a complex solution to be accepted.\n",
    "            - round_sig_digits (float): Number of significant digits to either separate two different solutions or merge them as one.\n",
    "            \n",
    "    Returns:\n",
    "        tuple:\n",
    "            A tuple containing:\n",
    "            \n",
    "            - solution_df (pandas.DataFrame): DataFrame containing found solutions' information.\n",
    "            - label (str): A label describing the customized parameters used for the computation.\n",
    "            - metadata (dict): A dictionary containing input parameter values used in the computation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assign default values to missing keyword arguments for parameters\n",
    "    label_needed = False\n",
    "    if 'par' in kwargs:\n",
    "        par = kwargs['par']\n",
    "        if par['label'] == '':\n",
    "            label_needed = True\n",
    "    else:\n",
    "        par = default_pars.copy()\n",
    "        for key in par:\n",
    "            par[key] = kwargs.get(key, par[key])\n",
    "        if par != default_pars:\n",
    "            label_needed = True\n",
    "    # Creating a label for parameters if needed\n",
    "    if label_needed:\n",
    "        # default_pars[key], par['label'] = 0 , 0\n",
    "        # differing_pairs = {key: value for key, value in par.items() if not np.isclose(value, default_pars[key])}\n",
    "        differing_pairs = {}\n",
    "        for key, value in par.items():\n",
    "            if key != 'label':\n",
    "                if not np.isclose(value, default_pars[key]):\n",
    "                    differing_pairs[key] = value\n",
    "        par['label'] = '_'.join([f\"({key}_{value:.3g})\" for key, value in differing_pairs.items()])\n",
    "    \n",
    "    global global_par # Store 'par' as a global variable\n",
    "    global_par = par # So that it can be accessed by char_eq(x), without being passed to it\n",
    "            \n",
    "    # Assign default values to missing keyword arguments for initial guess values\n",
    "    if 'guess_single' in kwargs:\n",
    "        guess_single_r = np.real(kwargs['guess_single'])\n",
    "        guess_single_i = np.imag(kwargs['guess_single'])\n",
    "\n",
    "        guess_range_real = [guess_single_r, guess_single_r, 1]\n",
    "        guess_range_imag = [guess_single_i, guess_single_i, 1]\n",
    "    else:\n",
    "        guess_range_real = kwargs.get('guess_range_real', [-300,50,700])\n",
    "        guess_range_imag = kwargs.get('guess_range_imag', [0,250,500])\n",
    "    \n",
    "    # Assign default values to the rest of missing keyword arguments\n",
    "    tol_fsolve = kwargs.get('tol_fsolve', 1e-15)\n",
    "    tol_is_sol = kwargs.get('tol_is_sol', 1e-6)\n",
    "    round_sig_digits = kwargs.get('round_sig_digits', 4)\n",
    "\n",
    "    metadata = {\n",
    "        'par' : par,\n",
    "        'guess_range' : (guess_range_real, guess_range_imag),\n",
    "        'tols' : (tol_fsolve, tol_is_sol, round_sig_digits)\n",
    "    }\n",
    "\n",
    "    # Constructiong a dictionary to capture legit solutions\n",
    "    solution_dict = {\n",
    "        'Sol_r':[],'Sol_i':[],'Guess_r':[],'Guess_i':[],'g(x)':[]\n",
    "        }\n",
    "\n",
    "    # Constructiong a 2D (Re-Im plane) mesh for different initial guess values\n",
    "    mesh_builder = np.meshgrid(\n",
    "        np.linspace(guess_range_real[0],guess_range_real[1],guess_range_real[2]),\n",
    "        np.linspace(guess_range_imag[0],guess_range_imag[1],guess_range_imag[2])\n",
    "        )\n",
    "    mesh = mesh_builder[0] + mesh_builder[1] * 1j\n",
    "    \n",
    "    for i in mesh:\n",
    "        for m in i:\n",
    "            m = np.array([m.real, m.imag]) # obtaining an initial guess from the mesh as a complex number\n",
    "            solution_array = opt.fsolve(char_eq,m,xtol=tol_fsolve)\n",
    "            is_sol = char_eq(solution_array) # evaluationg the value of char_eq at the obtained relaxed solution\n",
    "            is_sol = abs(complex(is_sol[0],is_sol[1]))\n",
    "            if np.isclose(is_sol,0,atol=tol_is_sol):\n",
    "                solution_dict['Guess_r'].append(m[0])\n",
    "                solution_dict['Guess_i'].append(m[1])\n",
    "                solution_dict['g(x)'].append(is_sol)\n",
    "                solution_dict['Sol_r'].append(solution_array[0])\n",
    "                solution_dict['Sol_i'].append(solution_array[1])\n",
    "                solution_array_conj_guess = solution_array.copy()\n",
    "                solution_array_conj_guess[1] *= -1\n",
    "                solution_array_conj = opt.fsolve(char_eq,solution_array_conj_guess,xtol=tol_fsolve)\n",
    "                is_sol_conj = char_eq(solution_array_conj) # evaluationg the value of char_eq at the obtained relaxed solution\n",
    "                is_sol_conj = (abs(complex(is_sol_conj[0],is_sol_conj[1])))\n",
    "                if np.isclose(is_sol_conj,0,atol=tol_is_sol):\n",
    "                    solution_dict['Guess_r'].append(m[0])\n",
    "                    solution_dict['Guess_i'].append(-m[1])\n",
    "                    solution_dict['g(x)'].append(is_sol_conj)\n",
    "                    solution_dict['Sol_r'].append(solution_array_conj[0])\n",
    "                    solution_dict['Sol_i'].append(solution_array_conj[1])\n",
    "    \n",
    "    del global_par # Avoid storing a global parameter after making use of it\n",
    "\n",
    "    solution_df = process_dataframe(pd.DataFrame(solution_dict), round_sig_digits)\n",
    "    solution_df = solution_df.sort_values(by=['Sol_r'], ascending=False)\n",
    "    return (solution_df, par['label'], metadata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalue Distribution Analysis\n",
    "\n",
    "In this step, we want to evaluate system's eigenvalues. Furthermore, we are interested in the effects of system parameters on its eigenvalue distribution. First, we obtain the eigenvalue distribution for a system with default parameters, a.k.a. the default system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve and plot for default_par\n",
    "df, label, metadata = find_eig()\n",
    "\n",
    "plot_single_df(df, label, metadata, filter=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we change the default parameters and define new parameter sets to obtain new systems. Then we call the solver function using the customized parameter values to see how changing each parameter will affect the eigenvalue distribution of the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pars_list = create_custom_pars_list('pars_list.csv')\n",
    "for par in pars_list:\n",
    "    df, label, metadata = find_eig(par=par)\n",
    "    save_dataframe_to_csv(df, label, 'CSV', metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_multiple_datasets('CSV')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rOp8yHdiv26a",
    "C1l2-KpYqZSK"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
